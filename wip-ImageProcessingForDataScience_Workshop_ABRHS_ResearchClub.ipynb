{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b51a7c-9fc8-471d-bad8-e84200bd913c",
   "metadata": {},
   "source": [
    "# Hands-on introduction to image processing for data science and deep learning.\n",
    "###### Author and Instructor: __Matei Iordanescu__\n",
    "Concepts:\n",
    "1)  [What is an image?](#Concept-1:-What-is-an-image?)  \n",
    "2)  [Meet Lena](#Concept-2:-Meet-Lena)  \n",
    "3)  [What actually is an image?](#Concept-3:-What-actually-is-an-image?)  \n",
    "4)  [The most basic coding pattern for image processing](#Concept-4:-The-most-basic-coding-pattern-for-image-processing)  \n",
    "5)  [Real example of image processing](#Concept-5:-Real-example-of-image-processing)  \n",
    "6)  [Kernel convolution](#Concept-6:-Kernel-convolution)  \n",
    "    -1) [Vertical edges](#1:-Vertical-edges)  \n",
    "    -2) [Horizontal edges](#2:-Horizontal-edges)  \n",
    "    -3) [Blurring](#3:-Blurring)  \n",
    "    -4) [Sharpening](#4:-Sharpening)  \n",
    "    -5) [Embossing](#5:-Embossing)\n",
    "7)  [Edge Detection](#Concept-7:-Edge-Detection)  \n",
    "8)  [Connection to DeepLearning](#Concept-8:-Connection-to-DeepLearning)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6e747-979b-4618-ab5f-ab5911c9a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77171a78-944c-450e-b45d-b4e57c7034ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae97be-d6e0-41f6-875a-3ea83a017efc",
   "metadata": {},
   "source": [
    "## Concept 1: What is an image?\n",
    "An image starts as a file saved on a disk in a computer. To read the image, you can use any programing language and leverage any image libraries. Here we use Python and Pillow (PIL for short), a Python library. After reading an image with PIL, you get a PIL image object which has many methods and properties you can query to understand and manipulate your image. For example, you can get the size of the image using the size function or you can display it using the display function.  \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ed9fb-4dc7-4776-b11a-726279c3f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/Data/Lena_Colored.jpeg\" \n",
    "img = Image.open(path)\n",
    "width, height=img.size\n",
    "display(img)\n",
    "width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912984f-c9d9-48a6-8c89-dc78bbbdd4a7",
   "metadata": {},
   "source": [
    "## Concept 2: Meet Lena\n",
    "Lenna (or Lena) is a standard test image used in the field of digital image processing, starting in 1973. It is a picture of the Swedish model Lena ForsÃ©n, shot by photographer Dwight Hooker and cropped from the centerfold of the November 1972 issue of Playboy magazine.\n",
    "[__Who is Lena__](https://www.google.com/search?q=who+is+lena+in+image+processing&sca_esv=deba1d0118d8a222&rlz=1C1OPNX_enUS1124US1125&biw=1536&bih=730&sxsrf=ADLYWIKGnvQrjBs_HkfopC1miBK1yLWjkQ%3A1732911290226&ei=uiBKZ6C2Dcqp5NoPrfffsQI&ved=0ahUKEwig-4XPrYKKAxXKFFkFHa37NyYQ4dUDCA8&uact=5&oq=who+is+lena+in+image+processing&gs_lp=Egxnd3Mtd2l6LXNlcnAiH3dobyBpcyBsZW5hIGluIGltYWdlIHByb2Nlc3NpbmcyCBAhGKABGMMEMggQIRigARjDBEiFDFC_B1jtCnABeAGQAQCYAWugAdEBqgEDMC4yuAEDyAEA-AEBmAIDoALdAcICChAAGLADGNYEGEfCAggQABiABBiiBJgDAIgGAZAGCJIHAzEuMqAHqQc&sclient=gws-wiz-serp)  \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c99af-ca0f-4a44-8cc3-0bde8686235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba41a4-e14f-45e4-9fef-de7623f54088",
   "metadata": {},
   "source": [
    "## Concept 3: What actually is an image?\n",
    "An image is an array of pixels, with each pixel being a tuple with three values corresponding to its respective R, G, and B color intensities, each typically ranging from 0-255. To find a certain pixel in an image using the PIL library, you give two indices (which correspond to rows and columns) to a function, just like any other image library. \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40361ffe-5cdf-4f7d-ac3b-d90036e865ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guestimate of a blue-ish pixel\n",
    "p = img.getpixel((450, 100))\n",
    "red_intensity = p[0]\n",
    "green_intensity = p[1]\n",
    "blue_intensity = p[2]\n",
    "red_intensity,green_intensity,blue_intensity\n",
    "\n",
    "# guestimate of a red-ish pixel\n",
    "p = img.getpixel((50, 100))\n",
    "red_intensity = p[0]\n",
    "green_intensity = p[1]\n",
    "blue_intensity = p[2]\n",
    "red_intensity,green_intensity,blue_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b2340-6ed9-422a-b527-f30d4cf9f398",
   "metadata": {},
   "source": [
    "## Concept 4: The most basic coding pattern for image processing\n",
    "The most basic pattern is two embedded loops that iterate over an image's rows and columns. \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d869a3f-f5b8-451a-99a2-3103d85498c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DuplicateImg(img):\n",
    "    width, height=img.size\n",
    "    newimg = Image.new(\"RGB\", (width, height), \"white\")\n",
    "    for row_counter in range(0, height):\n",
    "        for column_counter in range(0, width):\n",
    "            p = img.getpixel((row_counter, column_counter))\n",
    "            newimg.putpixel((row_counter,column_counter),p)\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e2d92-18c3-4f8a-a6ae-d4865803b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DuplicateImg(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f2b1d-e7dc-4349-8092-a4011cb0cfc3",
   "metadata": {},
   "source": [
    "## Concept 5: Real example of image processing\n",
    "### Thresholding:\n",
    " - One of the simplest example of image processing\n",
    " - Here we generate a black and white image\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00248b28-36d6-4e8d-a3fa-f3044d845d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Threshold(img, threshold):\n",
    "    width, height=img.size\n",
    "    newimg = Image.new(\"RGB\", (width, height), \"white\")\n",
    "    \n",
    "    for row_counter in range(0, height):\n",
    "        for column_counter in range(0, width):\n",
    "            p = img.getpixel((row_counter-1, column_counter-1))\n",
    "            r = p[0]\n",
    "            g = p[1]\n",
    "            b = p[2]\n",
    "            if ((r + g + b)/3)>=threshold:\n",
    "                newimg.putpixel((row_counter,column_counter),(255,255,255))\n",
    "            else:\n",
    "                newimg.putpixel((row_counter,column_counter),(0,0,0))\n",
    "    return(newimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06844fb6-f0a5-4744-9a5d-49c8fd153eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)\n",
    "Threshold(img, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1e42e-4e70-4ba0-83e9-165be17ff427",
   "metadata": {},
   "source": [
    "## Concept 6: Kernel convolution\n",
    "\n",
    "In this tutorial, we will focus on kernel convolution which is a more advanced and powerful type of image-processing technique. Kernel convolution involves an N by N matrix (also called a kernel), with a matching N by N sliding window in the image.  \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28374e-1063-43bc-ac47-ad5344df2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(nparray: np.ndarray, maxv: float=255):\n",
    "    nparray0 = nparray.astype(np.float64)\n",
    "    width= nparray0.shape[0]\n",
    "    height= nparray0.shape[1] \n",
    "    min_intensity = nparray.min()\n",
    "    max_intensity = nparray.max()\n",
    "    newnparray = maxv* (nparray0 - min_intensity)/(max_intensity - min_intensity)\n",
    "    return newnparray\n",
    "    \n",
    "def ConvolveImgKer(img, kernel):\n",
    "    width, height=img.size\n",
    "    newimgnparray = np.zeros(((height-2), (width-2), 3)).astype(np.float64)\n",
    "    float_kernel = [[float(x) for x in sublist] for sublist in kernel]\n",
    "    for row_counter in range(1, height-1):\n",
    "        for column_counter in range(1, width-1):\n",
    "            Gp=0\n",
    "            p = img.getpixel((row_counter-1, column_counter-1))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[0][0]\n",
    "            p = img.getpixel((row_counter-1, column_counter))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[0][1]\n",
    "            p = img.getpixel((row_counter-1, column_counter+1))\n",
    "            Gp += float((p[0] + p[1] + p[2])/3)*float_kernel[0][2]\n",
    "            p = img.getpixel((row_counter, column_counter-1))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[1][0]\n",
    "            p = img.getpixel((row_counter, column_counter))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[1][1]\n",
    "            p = img.getpixel((row_counter, column_counter+1))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[1][2]\n",
    "            p = img.getpixel((row_counter+1, column_counter-1))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[2][0]\n",
    "            p = img.getpixel((row_counter+1, column_counter))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[2][1]\n",
    "            p = img.getpixel((row_counter+1, column_counter+1))\n",
    "            Gp += (float(p[0] + p[1] + p[2])/3)*float_kernel[2][2]\n",
    "            newimgnparray[column_counter-1][row_counter-1][0]=Gp\n",
    "            newimgnparray[column_counter-1][row_counter-1][1]=Gp\n",
    "            newimgnparray[column_counter-1][row_counter-1][2]=Gp\n",
    "    return Image.fromarray(Normalize(newimgnparray).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa60c2-3064-403f-b81a-70d8217c96ab",
   "metadata": {},
   "source": [
    "### Practical examples: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74324168-0edd-4bb6-9a92-a904be2a83a4",
   "metadata": {},
   "source": [
    "#### 1: Vertical edges\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5e89d-2a18-49ad-bb4b-3704af43dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=[[0,-1,0],[0,0,0],[0,1,0]]\n",
    "convolvedimg=ConvolveImgKer(img, kernel)\n",
    "display(convolvedimg)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f9dfa-23ba-41f8-a585-878fac035f45",
   "metadata": {},
   "source": [
    "#### 2) Horizontal edges\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c39b8f-0900-4b4c-994d-a7cd1d962401",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=[[0,0,0],[-1,0,1],[0,0,0]]\n",
    "convolvedimg=ConvolveImgKer(img, kernel)\n",
    "display(convolvedimg)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe1ee3-34ca-4d2a-a905-d6998bcde96a",
   "metadata": {},
   "source": [
    "#### 3: Blurring\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fedb48-379d-4e24-b8c6-302dd9b62576",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=[[1,1,1],[1,1,1],[1,1,1]]\n",
    "path = \"/workspace/Data/Lena.jpeg\" \n",
    "img_small = Image.open(path)\n",
    "convolvedimg=ConvolveImgKer(img_small, kernel)\n",
    "for counter in range(10):\n",
    "    convolvedimg=ConvolveImgKer(convolvedimg, kernel)\n",
    "display(convolvedimg)\n",
    "display(img_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc5631-b3b7-484f-9779-ceefea22042c",
   "metadata": {},
   "source": [
    "#### 4: Sharpening  \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2a03b-a75e-4262-82ee-8e14d6e1a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=[[0,-1,0],[-1,5,-1],[0,-1,0]]\n",
    "convolvedimg=ConvolveImgKer(img, kernel)\n",
    "display(convolvedimg)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05138eeb-9e6a-49a3-a113-c0eb69033f48",
   "metadata": {},
   "source": [
    "#### 5: Embossing  \n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753eea0-e39a-498f-96eb-c8530f9a9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=[[-2,-1,0],[-1,1,1],[0,1,2]]\n",
    "convolvedimg=ConvolveImgKer(img, kernel)\n",
    "display(convolvedimg)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bedd5-cf2e-4e8a-90bd-0d83559a964e",
   "metadata": {},
   "source": [
    "## Concept 7: Edge Detection\n",
    "\n",
    "Leverage the gradient to detect edges at all angles\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fdc01-5a40-4e66-8721-7f4ddc838509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientMagnitude(img):\n",
    "    width, height=img.size\n",
    "    newimg = Image.new(\"RGB\", (width-2, height-2), \"white\")\n",
    "    for row_counter in range(1, height-1):\n",
    "        for column_counter in range(1, width-1):\n",
    "            p1 = img.getpixel((row_counter, column_counter-1))\n",
    "            p2 = img.getpixel((row_counter, column_counter+1))\n",
    "            Gx=((p2[0] + p2[1] + p2[2])/3)-((p1[0] + p1[1] + p1[2])/3)\n",
    "            p1 = img.getpixel((row_counter-1, column_counter))\n",
    "            p2 = img.getpixel((row_counter+1, column_counter))\n",
    "            Gy=((p2[0] + p2[1] + p2[2])/3)-((p1[0] + p1[1] + p1[2])/3)\n",
    "            magnitude=math.sqrt((Gx * Gx) + (Gy * Gy))\n",
    "            magnitude = int(magnitude)\n",
    "            newimg.putpixel((row_counter-1,column_counter-1),(magnitude,magnitude,magnitude))\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46ffeb-8400-4c89-a4c8-82905bd6f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientMagnitude(img)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66e5fe-9e7c-4067-b69a-d579402de86b",
   "metadata": {},
   "source": [
    "## Concept 8: Connection to DeepLearning\n",
    "\n",
    "### Machine Learning (ML):\n",
    "\n",
    "- A class of algorithms that learn thresholds from input data.\n",
    "- Creates models to classify new, unseen data.\n",
    "\n",
    "### Artificial Neural Networks (ANN):\n",
    "\n",
    "- A subset of ML using artificial neurons grouped in layers.\n",
    "- Performs learning tasks by mimicking brain-like processes.\n",
    "\n",
    "\n",
    "### Deep Learning (DL):\n",
    "\n",
    "- A specialized class of ANN utilizing many layers.\n",
    "- Employs Convolutional Neural Networks (CNNs) to identify image patterns, similar to kernel convolution.\n",
    "\n",
    "### Why are the image processing concepts covered here relevant to DeepLearning:\n",
    "\n",
    "- Builds a foundation for understanding the mechanics of deep learning.\n",
    "- Explains how deep learning effectively extracts relevant information from images.\n",
    "\n",
    "Back to [Summary](#Hands-on-introduction-to-image-processing-for-data-science-and-deep-learning.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
